% \documentclass[CEJM,DVI]{cej} % use DVI command to enable LaTeX driver
\documentclass[CEJM,PDF]{Class+Reg_in_Molec_Docking} % use PDF command to enable PDFLaTeX driver
\usepackage{layout}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{graphicx}
\usepackage{multirow}

\hypersetup{unicode=true}



\def\lorem{Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.}

\def\LOREM{\lorem \\ \lorem}



\title{Решение задачи оптимизации, сочетающей классификацию и регрессию, в применении к молекулярному докингу}

\articletype{Joint Convex Learning} % Research Article, Review Article, Communication, Erratum




\author{Бишук Антон$_{\;1}$\email{bishuk.ayu@phystech.edu},
        Кадукова Мария$_{\;2, 3}$\email{mn.kadukova@gmail.com},
        Грудинин Сергей$_{\;2}$\email{sergei.grudinin@gmail.com}
       }

\shortauthor{А. Бишук, М. Кадукова, С. Грудинин}

\institute{\inst{1}
           Факультет Управления Прикладной Математики и Информатики, Московский Физико-Технический Институт
           \inst{2}
           Univ. Grenoble Alpes, CNRS, Inria, Grenoble INP, LJK, 38000 Grenoble, France
           \inst{3}
           Центр исследований молекулярных механизмов старения и возрастных заболеваний, Московский Физико-Технический Институт
          }

\abstract{В работе рассматривается задача предсказания нативной конформации белка и лиганда. Решение задачи происходит путем поиска минимальной свободной энергии связи молекулы белка с лигандом. Для этого оптимизируется скоринг--функция, включающая в себя классификацию, базирующуюся на методе опорных векторов(SVM), и регрессию с различными функциями потерь. Проверка тезисов будет осуществляться на данных, состоящих из комплексов белков и лигандов, для которых необходимо определить наилучшую позу лиганда или предсказать свободную энергию связывания.
}

\keywords{Лиганд -- белок \*\ скоринговая функция \*\ свободная энергия связывания \*\ классификация \*\ регрессия }

\msc{XXXXX, YYYYY}

\begin{document}

\maketitle
%\baselinestretch{2}
%------------------------------------------------------------------------------------
\section{Введение }

\hspace{0.5cm}Растущая потребность в открытии более эффективных лекарственных средств стимулирует развитие новых подходов в молекулярном моделировании. \cite{mannhold2011virtual}. Молекулярный докинг является одной важных задач молекулярного моделирования. Он заключается в предсказании взаимной ориентации молекул, наиболее выгодной для образования устойчивого комплекса \cite{lengauer1996computational}. Молекулярный докинг -- это метод молекулярного моделирования, который позволяет предсказать наиболее выгодную для образования устойчивого комплекса ориентацию молекул. Он порождает огромное пространство признаков за счет большого числа степеней свободы системы. Для решения данной задачи необходимо проводить анализ и обработку большого объема данных, в связи с чем задача является вычислительно сложной, а значит требует решений с высокой производительностью.   

\hspace{0.5cm}Образование комплекса <<белок -- лиганд>> является термодинамическим событием, описываемым константой связывания. Она напрямую зависит от свободной энергией связывания. Так, минимуму энергии связывания соответствует нативная конформация. Свободная энергия связывания зависит от множества факторов, строгий подсчет которых требовал бы сэмплирования всего конфигурационного пространства, что в свою очередь является вычислительно сложной задачей в силу высокой размерности пространства\cite{kadukova2017convex}. Для решения задачи нахождения минимальной энергии в последние годы был предложен ряд аппроксимирующих алгоритмов, базирующихся на скоринговых функциях\cite{meng2011molecular} для оценки энергии связывания белка и лиганда.

Convex-PL обучается через задачу классификации, суть которой в том, чтобы разделить нативную и ненативную конформацию системы, состоящей из белка и лиганда. Энергия, предсказанная Convex-PL, должна быть минимальна для нативной конформации.


\hspace{0.5cm}Одним из таких методов является Convex-PL\cite{kadukova2017convex}. Он классифицирует конформации системы, состоящей из белка и лиганда, на нативные и ненативные. Происходит это в том предположении, что нативной конформации соответствует минимальная энергия связывания. Основная идея метода Convex-PL состоит в представлении белка и лиганда в виде конечного набора точек и последующего подсчета функционала, которым в данном случае является свободная энергия связывания, на всевозможных комбинациях различных пар атомов. Однако этот метод имеет недостаток в лице недостаточной корреляции между реальной энергией связывания и полученной из решения оптимизационной задачи \cite{boyd2004convex}. Для устранения этого недостатка предлагается использовать метод, совмещающий в себе как бинарную классификацию, так и  регрессию.

%------------------------------------------------------------------------------------
\section{Модель взаимодействий}

\hspace{0.5cm}Пусть имеется $P$ нативных комплексов белков-лигандов $\{C_{i1}\}_{i=1}^P$. Применив к лигандам изометрические преобразования, сгенерируем для каждой нативной позы $D-1$ ненативных поз $\{C_{ij}\}_{i=1,j=2}^{\text{P},\text{D}}$. Таким образом, для каждого из $P$ комплексов имеем $D$ конформаций: одну нативную и $D-1$ ненативных. Требуется найти скоринговый функционал $E$, который удовлетворяет следующим неравенствам:

\begin{equation}\label{eq1}
E(C_{i1}) < E(C_{ij}) \ \forall i\in\{1,\dots,P\}, \ \forall j\in\{2,\dots,D\}.
\end{equation}

\hspace{0.5cm}В качестве такого функционала будем рассматривать свободную энергию связывания белков с лигандами, определенную для всех возможных комплексов. Сделаем ряд допущений для упрощения формы функционала.

\hspace{0.5cm}Во-первых, будем рассматривать комплекс <<белок-лиганд>> как набор атомов, каждый из которых имеет некоторый тип. Тип каждого атома зависит от его химических свойств, таких как номер элемента в периодической таблице, принадлежность к ароматической функциональной группе, гибридизация, полярность и т.д. Пусть $M_1$ -- число типов атомов белка, а $M_2$ -- число типов атомов лиганда. Тогда всего получим $M_1\times M_2$ различных атомных взаимодействий.

\hspace{0.5cm}Во-вторых, будем считать, что скоринговый функционал $E$ определяется только взаимодействиями между парами атомов рассматриваемого комплекса. При этом в каждой паре первый атом является атомом лиганда, а второй -- атомом белка. Кроме того, будем рассматривать только те пары, в которых расстояние между атомами не превышает некоторой пороговой величины $r_{\max}$. В качестве $r_{\max}$ возьмем значение $7$\AA, что отличается от значения в $10$\AA, как это было сделано в других работах \cite{rmax1,rmax2,rmax3,rmax4,rmax5,rmax6}. Такое решение было принято для уменьшения размерности данных, однако в дальнейшем, эту условность можно опустить, тогда следует ожидается улучшение результатов. 

\hspace{0.5cm}В-третьих, будем считать, что $E$ зависит только от распределения расстояний между взаимодействующими атомами.

\hspace{0.5cm}И, наконец, предположим, что $E$ является линейным функционалом и имеет следующий вид: 
\begin{equation}\label{eq2}
E(n(r)) = \sum_{k=1}^{M_1}\sum_{l=1}^{M_2}\int\limits_{0}^{r_{max}}n^{kl}(r)f^{kl}(r)dr,
\end{equation}
здесь $f^{kl}(r)$ -- неизвестные функции взаимодействия между атомами типов $k$ и $l$. Будем называть их \textit{скоринговыми потенциалами},а функции $n^{kl}(r)$ -- численными плотностями распределений пар атомов типов $k$ и $l$ по расстоянию $r$ между ними: 
\begin{equation}\label{eq3}
n^{kl}(r) = \sum_{i,j} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left[{-\frac{(r-r_{ij})^2}{2\sigma^2}}\right],
\end{equation}
где $\sigma^2$ -- стандартное отклонение (константа). Сумма берется по всем парам $(i, j)$ атомов с типами $k$ и $l$ соответственно, у которых расстояние между атомами не превышает пороговой величины $r_{\max}$, атом $i$ принадлежит лиганду, а атом $j$ -- белку.

Разложим неизвестные скоринговые потенциалы $f^{kl}(r)$ и плотности $n^{kl}(r)$ по полиномиальному базису: 
\begin{equation}\label{eq4}
\begin{split}
f^{kl}(r) & = \sum_{q} w_q^{kl}\psi_q(r), \\
n^{kl}(r) & = \sum_{q} x_q^{kl}\psi_q(r),
\end{split}
\end{equation}
где $\psi_q(r)$ -- ортогональные базисные функции на интервале $[0, r_{\max}]$, а $w_q^{kl}$ и $x_q^{kl}$ -- коэффициенты разложения функций $f^{kl}(r)$ и $n^{kl}(r)$ соответственно. Поскольку базисные функции ортогональны, справедливо следующее соотношение:

\begin{equation}\label{eq5}
\int\limits_{0}^{r_{\text{max}}}\psi_i(r)\psi_j(r)\Omega(r)dr = \delta_{ij}, \ r\in[0,r_{\text{max}}],
\end{equation}
где $\Omega(r)$ -- некоторая неотрицательная весовая функция на $[0,r_{\text{max}}]$, $\delta_{ij}$ -- символ Кронекера. Из данного условия \eqref{eq5} ортогональности базисных функций могут быть найдены коэффициенты раложения $w_q^{kl}$ и $x_q^{kl}$:
\begin{equation}\label{eq6}
\begin{split}
w_q^{kl}=\int\limits_{0}^{r_{\text{max}}}f_{kl}(r)\psi_q(r)dr, \\
x_q^{kl}=\int\limits_{0}^{r_{\text{max}}}n_{kl}(r)\psi_q(r)dr,
\end{split}
\end{equation}

Таким образом, функционал $E$ можно записать в следующем виде:
\begin{equation}\label{eq7}
E(n(r)) = \sum_{k=1}^{M_1} \sum_{l=1}^{M_2} \sum_{pq}^{\infty}w_q^{kl}x_p^{kl}\int\limits_{0}^{r_{\text{max}}}\psi_q(r)\psi_p(r)\Omega(r)dr.
\end{equation}

Учитывая условие ортогональности \eqref{eq5} и ограничиваясь порядком разложения Q, получаем приближенное выражение скорингового функционала: 
\begin{equation}\label{eq8}
\begin{split}
E(n(r)) \approx \sum_{k=1}^{M_1} & \sum_{l=1}^{M_2} \sum_{q=0}^{Q}w_q^{kl}x_q^{kl} = \langle\mathbf{w},\mathbf{x}\rangle,\\
\mathbf{w}, \mathbf{x} & \in \mathbb{R}^{Q\times M_1\times M_2}.
\end{split}
\end{equation}

Неизвестный вектор $\mathbf{w}$ будем называть \textit{скоринговым вектором}, а вектор $\mathbf{x}$ -- \textit{структурным вектором}. Структурный вектор можно получить из кристаллографических данных. Для оценки энергии связывания в работе \cite{grudinin2016predicting} использовался порядок разложения $Q=10$, и рассматривались $M_1 = 23$ и $M_2 = 40$ типов атомов.

%------------------------------------------------------------------------------------
\section{Постановка задачи}

\hspace{0.5cm}С точки зрения биоинформатики, задача заключается в оценке свободной энергии связывания белка с маленькой молекулой (лигандом): лиганд, наиболее подходящий для связи с белком, в своем наилучшем положении имеет \textbf{наименьшую свободную энергию} взаимодействия с молекулой белка. Для нахождения такого лиганда и его энергии связывания будем решать две задачи: бинарную классификацию (SVM) и регрессию. 

\hspace{0.5cm}Заранее обозначим $\mathbf{X}_i$ -- \textbf{i}-ая строка матрицы признаков \textbf{X}, матрица $\overset{nat}{\mathbf{X}}$ -- матрица признаков для комплексов в натиных конформациях. Важно отметить, что для каждого комплекса существует \underline{единственная <<нативная>>} поза с меткой $y = 1$ и \underline{$\text{D}-1$ <<ненативная>>} с меткой $y = -1$.

\subsection{Классификация поз на нативные и ненативные}

Для поиска вектора $\mathbf{w}$, имеющего значение энергии взаимодействия, решается следующая задача классификации: 
\begin{eqnarray}\label{SVM} 
\begin{tabular}{lc}
$\underset{\mathbf{w}, b_i, \xi_{i}}{\text{Minimize: }}$&$ \frac{1}{2} \mathbf{w}^T\mathbf{w} + C\sum\limits_{i}\xi_{i}$ \\ 
\multirow{3}{*}{Subject to:}
&$y_{i}[\mathbf{w}^T\mathbf{X}_{i} - b_j]-1+\xi_{i} \geq 0$\\%, ~ i=1...P,~j=1...D$ \\
&$\xi_{i} \geq 0$,
\end{tabular}
\label{eq:primal} 
\end{eqnarray}
где: \textbf{w}, $b_j$ -- переменные невязки; $\xi_{i}$ -- оптимизируемые параметры модели; C -- некоторый коэффициент регуляризации; P -- число комплексов белок-лиганд; D -- число взаимных положений (поз) белка и лиганда в каждом из комплексов; $j = 1,\hdots,\text{P}$; $i = 1,\hdots,\text{P}\cdot \text{D}$.


\subsection{Предсказание энергии связывания}

\hspace{0.5cm}Для каждого комплекса известно значение $s_i$, соответствующее энергии связывания i-ой нативной конформации, полученной в эксперименте. Его также можно предсказывать, используя для обучения матрицу признаков $\overset{nat}{\mathbf{X}}$ нативных поз. Тем самым получаем задачу регрессии предсказания энергии связывания:

\begin{eqnarray}\label{Reg} 
\begin{tabular}{lc}
$\underset{\mathbf{w}}{\text{Minimize: } }$&$ \sum\limits_{i}\|\mathbf{w}^T\overset{nat}{\mathbf{X}_i} - s_i\|^2 + \alpha\|\mathbf{w}\|^2$, \\ 
\end{tabular}
\label{eq:primal} 
\end{eqnarray}

где: $\alpha$ -- коэффициент регуляризации ridge-регрессии.


\subsection{Итоговая задача}

Таким образом, после объединение задач \ref(SVM) и \ref(Reg) требуется решить следующую оптимизационную задачу:

\begin{eqnarray}\label{Class+Regres} 
\begin{tabular}{lc}
$\underset{\mathbf{w}, b_i, \xi_{i}}{\text{Minimize: }}$ &$ \frac{1}{2} \mathbf{w}^T\mathbf{w} + C\sum\limits_{i}\xi_{i} + C_{r}\sum\limits_{i} f(\overset{nat}{\mathbf{X}_i},\mathbf{w}, s_i)$ \\ 
\multirow{3}{*}{Subject to:}
&$y_{i}[\mathbf{w}^T\mathbf{X}_{i} - b_j]-1+\xi_{i} \geq 0$\\
&$\xi_{i} \geq 0$
\end{tabular}
\label{eq:primalboth} 
\end{eqnarray}
Здесь $f(\overset{nat}{\mathbf{X}_i},\mathbf{w}, s_i)$ -- функция потерь регрессии, например, \textit{Mean Squared Error}, $C_r$ -- коэффициент регуляризации для функции потерь регрессии.

%------------------------------------------------------------------------------------
\section{Решение оптимизационной задачи}

В уравнении \ref{Class+Regres} будем принимать за функцию потерь регресии MSE:
\begin{eqnarray}\label{MSE} 
\begin{tabular}{lc}
$f\left(\overset{nat}{\mathbf{X}_i},\mathbf{w},s_i\right) = \left(\langle \overset{nat}{\mathbf{X}_i},w \rangle - s_i\right)^2, \hspace{1cm} i = 1,\hdots,P .$
\end{tabular}
\end{eqnarray}

Тогда проведем ряд преобразований для нативных конформаций:
\begin{multline*}
\; \frac{1}{2}\left\|\mathbf{w}\right\|^2 + C_r\sum_{i=1}^{P} f\left(\overset{nat}{\mathbf{X}_i},\mathbf{w},s_i\right) = \frac{1}{2}\mathbf{w}^T\mathbf{w} + C_r \left\| \overset{nat}{\mathbf{X}}\mathbf{w}-\mathbf{s} \right\|^2 =\\
= \frac{1}{2}\mathbf{w}^T\mathbf{w} + C_r \mathbf{w}^T\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}}\mathbf{w} - 2C_r\mathbf{w}^T\overset{nat}{\mathbf{X}^T}\mathbf{s} + C_r\mathbf{s}^T\mathbf{s} =  \frac{1}{2}\mathbf{w}^T\left( \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right)\mathbf{w} - 2C_r\mathbf{w}^T\overset{nat\;\;\;}{\mathbf{X}^T}\mathbf{s} + C_r\mathbf{s}^T\mathbf{s} =\\
 = \frac{1}{2}\left\|\left[ \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right]^{\frac{1}{2}}\mathbf{w}\right\|^2 - 2C_r\left(\mathbf{w}^T\left[ \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right]^{\frac{1}{2}}\right)\left(\left[ \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right]^{-\frac{1}{2}}\overset{nat\;\;\;}{\mathbf{X}^T}\mathbf{s}\right) + C_r\mathbf{s}^T\mathbf{s} = \\
 = \frac{1}{2}\left( \left[ \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right]^{\frac{1}{2}}\mathbf{w} - 2C_r \left[ \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right]^{-\frac{1}{2}}\overset{nat\;\;\;}{\mathbf{X}^T}\mathbf{s}  \right)^2 + C_r\mathbf{s}^T\mathbf{s} - 2C_r^2\left\| \left[ \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right]^{-\frac{1}{2}}\overset{nat\;\;\;}{\mathbf{X}^T}\mathbf{s}\right\|^2.
\end{multline*}

Введем следующую замену:

\begin{eqnarray}\label{transform} 
\begin{tabular}{lc}
$\mathbf{A} = \left[ \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right]^{\frac{1}{2}}$\\
$\mathbf{d} = 2C_r\left[ \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right]^{-\frac{1}{2}}\overset{nat\;\;\;}{\mathbf{X}^T}\mathbf{s} = 2C_rA^{-1}\overset{nat\;\;\;}{\mathbf{X}^T}\mathbf{s}$\\
$\mathbf{w'} = \mathbf{Aw - d}$
\end{tabular}
\end{eqnarray}

Величина, стоящая вне квадрата, является константой, а потому не влияет на оптимизацию:

$$C_r\mathbf{s}^T\mathbf{s} - 2C_r^2\left\| \left[ \mathbf{I} + 2C_r\overset{nat\;\;\;}{\mathbf{X}^T}\overset{nat}{\mathbf{X}} \right]^{-\frac{1}{2}}\overset{nat\;\;\;}{\mathbf{X}^T}\mathbf{s} \right\|^2 = \text{const}$$

После замены получим следующую задачу оптимизации:

\begin{eqnarray}\label{Class+Regres_new} 
\begin{tabular}{lc}
$\underset{\mathbf{w}, b_i, \xi_{i}}{\text{Minimize: }}$ &$ \frac{1}{2} \|\mathbf{w'}\|^2 + C\sum\limits_{i}\xi_{i}$ \\ 
\multirow{3}{*}{Subject to:}
&$y_{i}[(\mathbf{A}^{-1}(\mathbf{w' + d}))^T\mathbf{X}_{i} - b_j]-1+\xi_{i} \geq 0$\\
&$\xi_{i} \geq 0$
\end{tabular}
\label{eq:primalboth} 
\end{eqnarray}

Важно отметить, что $\mathbf{X}_i$ -- i-ую строку матрицы $\mathbf{X}$ -- в терминах линейной алгебры следует воспринимать как столбец, а не как строку.

Построим двойственную задачу:

\begin{equation}
\begin{aligned}
&\mathcal{L}(\mathbf{w'}, \mathbf{d}, \mathbf{\xi}, \lambda, r) = \frac{1}{2} \|\mathbf{w'}\|^2 + C\sum\limits_{i=1}^{\text{P}\cdot\text{D}}\xi_{i} - 
\sum_{\underset{{j=nD}}{j=0}}^{\text{D}(\text{P}-1)}\sum_{i=1}^{\text{D}}{\lambda_{i} \left( y_{i}[\langle \mathbf{A}^{-1}\left(\mathbf{w}'+\mathbf{d}\right), \mathbf{X}_{i}\rangle - b_j]-1+\xi_{i} \right)} - \sum_{i=1}^{\text{P}\cdot\text{D}}{r_{i}\xi_{i}}, \\
& \hspace{1cm}\frac{\partial{\mathcal{L}}}{\partial{\mathbf{w'}}} = \mathbf{w'} - \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}y_{i}\langle \mathbf{A}^{-1}\left(\mathbf{w'}+\mathbf{d}\right), \mathbf{X}_{i} \rangle}'_{w'} = 0 \rightarrow \underline{\mathbf{w}' = \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}y_{i}\mathbf{A}^{-1} \mathbf{X}_{i}}} \\
& 
\hspace{1cm}\frac{\partial{\mathcal{L}}}{\partial{b_k}} = \underline{\sum_{j=1}^D{\lambda_{k+j}y_{k+j}} = 0}, \hspace{1cm} k \in \{ 0,\text{D},2\text{D},\hdots,\text{D}(\text{P} - 1) \},  \\
& \hspace{1cm}\frac{\partial{\mathcal{L}}}{\partial{\xi_{i}}} = C - \lambda_{i} - r_{i} = 0 \rightarrow \underline{\lambda_{i} + r_{i} = C}, \hspace{1cm} \forall i \in \{1,\hdots\text{P}\cdot\text{D}\}.
\end{aligned}
\end{equation}
\\
Подставим оптимальные значения параметров в лагранжиан.

\begin{equation}
\begin{aligned}
& \mathcal{L}(\lambda, r) = \frac{1}{2} \langle \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}y_{i}\mathbf{A}^{-1} \mathbf{X}_{i}}, \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}y_{i}\mathbf{A}^{-1} \mathbf{X}_{i}} \rangle + C\sum\limits_{i=1}^{\text{P}\cdot\text{D}}\xi_{i} - 
\sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i} y_{i}\langle \mathbf{A}^{-1} \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}y_{i} \mathbf{A}^{-1}  \mathbf{X}_{i}}, \mathbf{X}_{i}\rangle} - \\ 
& - \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i} y_{i}\langle \mathbf{A}^{-1}\mathbf{d}, \mathbf{X}_{i} \rangle} + \sum_{\underset{{j=nD}}{j=0}}^{\text{D}(\text{P}-1)}\sum_{i=1}^{\text{D}}{\lambda_{i+j} y_{i+j}b_j} + \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}}  - \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}\xi_{i}}- \sum_{i=1}^{\text{P}\cdot\text{D}}{r_{i}\xi_{i}} = \\
& = \frac{1}{2} \sum_{i=1}^{\text{P}\cdot\text{D}}\sum_{j=1}^{\text{P}\cdot\text{D}} {\lambda_{i}\lambda_{j}y_{i}y_{j}\langle \mathbf{A}^{-1} \mathbf{X}_{i}, \mathbf{A}^{-1} \mathbf{X}_{j} \rangle} + \sum_{i=1}^{\text{P}\cdot\text{D}}{\xi_{i}(C - \lambda_{i} - r_{i})} - \sum_{i=1}^{\text{P}\cdot\text{D}}\sum_{j=1}^{\text{P}\cdot\text{D}} {\lambda_{i}\lambda_{j}y_{i}y_{j}\langle \mathbf{A}^{-2} \mathbf{X}_{i},  \mathbf{X}_{j} \rangle} - \\
& - \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i} y_{i}\langle \mathbf{A}^{-1}\mathbf{d}, \mathbf{X}_{i} \rangle} + \sum_{\underset{{j=nD}}{j=0}}^{\text{D}(\text{P}-1)}b_j\sum_{i=1}^{\text{D}}{\lambda_{i+j} y_{i+j}} + \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}}
\end{aligned}
\end{equation}

Учитывая следующие замечания, получим выражение для лагранжиана и ограничений в задаче условной минимизации:

\begin{enumerate}
	\item $\sum\limits_{i=1}^{\text{P}\cdot\text{D}}{\xi_{i}(C - \lambda_{i} - r_{i})} = 0$ из ограничений;
	\item $\sum\limits_{i=1}^{P}{b_i \sum\limits_{j=1}^{D}{\lambda_{i+j} y_{i+j}}} = 0$ из ограничений;
	\item $\langle  \mathbf{A}^{-2} \mathbf{X}_i,  \mathbf{X}_i \rangle = \langle  \mathbf{A}^{-1} \mathbf{X}_i, \mathbf{A}^{-1} \mathbf{X}_i \rangle$, т.к. $\mathbf{X}_i^{\top}\mathbf{A}^{-2} \mathbf{X}_i =  \mathbf{X}_i^{\top}\mathbf{A}^{-1}\mathbf{A}^{-1} \mathbf{X}_i = (\mathbf{A}^{-1} \mathbf{X}_i)^{\top}\mathbf{A}^{-1} \mathbf{X}_i$;
	\item $\widehat{\mathbf{X}} \overset{\text{def}}{=} \mathbf{X}\mathbf{A}^{-1}$.
\end{enumerate}

\begin{equation}
\begin{aligned}
& \mathcal{L}(\lambda) = - \frac{1}{2} \sum_{i=1}^{\text{P}\cdot\text{D}}\sum_{j=1}^{\text{P}\cdot\text{D}} {\lambda_{i}\lambda_{j}y_{i}y_{j}\langle \widehat{\mathbf{X}}_{i}, \widehat{\mathbf{X}}_{j} \rangle} - 
\sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}y_{i}\langle \mathbf{A}^{-1}\mathbf{d}, \mathbf{X}_{i} \rangle} + \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i}} = \\
& = - \frac{1}{2} \sum_{i=1}^{\text{P}\cdot\text{D}}\sum_{j=1}^{\text{P}\cdot\text{D}} {\lambda_{i}\lambda_{j}y_{i}y_{j}\langle \widehat{\mathbf{X}}_{i}, \widehat{\mathbf{X}}_{j}  \rangle} + 
\sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i} \left(1  - y_{i}\langle \mathbf{d}, \widehat{\mathbf{X}}_{i} \rangle \right)}
\end{aligned}
\end{equation}

Двойственной задачей является $\underset{\lambda}{\text{argmax }} \mathcal{L}(\lambda)$.

Значит, исходная задача по теореме Каруша-Куна-Таккера эквивалентна следующей двойственной:
\begin{equation}\label{Class+Regres_final}
\begin{aligned}
& \underset{\lambda_{i}}{\text{minimize:}}
& & \frac{1}{2}\sum\limits_{(i,j)=1}^{\text{P}\cdot\text{D}}\lambda_{i}\lambda_{j}y_{i}y_{j}\langle \widehat{\mathbf{X}}_{i},\widehat{\mathbf{X}}_{j}\rangle + \sum_{i=1}^{\text{P}\cdot\text{D}}{\lambda_{i} \left(y_{i}\langle \mathbf{d}, \widehat{\mathbf{X}}_{i} \rangle - 1 \right)} \\
& \text{subject to:}
& & 0\leq\lambda_{i} \leq C, \\
&&& \sum_{j=1}^D{\lambda_{k+j}y_{k+j}} = 0, \\
&&& k \in \{ 0,\text{D},2\text{D},\hdots,\text{D}(\text{P}-1) \}. \\
\end{aligned}
\end{equation}

%------------------------------------------------------------------------------------
\section{Данные}

Данные представляют из себя размеченную матрицу признаков для 12,000 комплексов белков с лигандами, для каждого из которых известна одна нативная и 18 ненативных конформаций (декоев). Декои были сгенерированы путем поворотов и трансляций относительно нативной конформации с сохранением постоянного RMSD, равного 1~\AA~. Матрица признаков записана так, что кластеры из конформаций одного комплекса следуют друг за другом. 
В кластере всегда на первом месте стоит нативное положение, затем все ненативные.

\textbf{Данные для бинарной классификации}
\medskip

Основными признаками объектов являются гистограммы распределений расстояний между парами атомов белка и лиганда различных типов. Размерность вектора признаков составляет 6,440. Так же в данных есть вектор меток $\mathbf{y}$, у которого на месте нативной конформации стоит 1, а на месте ненативной конформации -1. Метки были присвоены конформациям в ходе экспериментов.

\textbf{Данные для регрессии}
\medskip
Для каждого из представленных комплексов известно значение величины, которую можно интерпретировать как энергию связывания. Это значение определено только для нативной позы лиганда в комплексе. 
%
Для задачи регрессии мы используем 379 дополнительных признаков для учета взаимодействий комплексов с растворителем и учета энтропийных потерь из-за ограничения подвижности лиганда. 65 из 379 признаков соответствуют площади поверхности, доступной растворителю, для каждого типа атома взаимодействующих атомов белка и лиганда. Следующие 315 признаков являются гистограммами распределений расстояний между взаимодействующими атомами белка, лиганда и пробными "атомами растворителя", которые мы расставляем по сетке вокруг комплекса. Энтропийные потери описываются "подвижностью" лиганда, рассчитанной как логарифм числа его стабильных конформаций.


%------------------------------------------------------------------------------------
\section{Эксперимент}
Для решения оптимизацонной задачи было решено использовать Оксфордский солвер OSQP\cite{osqp,osqp-codegen}, базирующийся на алгоритме ADMM\cite{osqp-infeasibility}.

\hspace{1cm} Первым этапом работы стала проверка того, что численное решение задачи при $C_r = 0$ соответствует решению, полученному для задачи SVM. Это условие могло не выполняться из-за накопления численных ошибок, вызванных неточностью операций над числами с плавающей точкой при поиске квадратного корня и обратной матрицы в (\ref{transform}) и (\ref{Class+Regres_new}). 

Далее важно было понять, действительно ли дополнительные признаки, которые были добавлены для задачи регрессии, улучшают корреляцию предсказанных энергий с экспериментальными значениями. Чтобы разделить проверку гипотез, было решено использовать такой набор данных, который не ухудшал классификацию, то при этом увеличивал корреляцию энергии. Поэтому в первую очередь было решено добавить всего один признак, который имеет одно значение для всех положений в комплексе. Таким образом влияние новых полученных данных на классификацию должно стать минимальным.
Таким образом, мы произвели вычисления для матрицы, состоящей только из признаков для классификации с добавлением признака, описывающего подвижность(flexibility). Добавление flexibility привело к улучшению корреляции.

Так же было замечено, что классификация не будет ухудшаться, если будет выполнено следующее условие: $\frac{C_r}{C}\gg1$.

Были проведены эксперименты и построены карты глубины для разных метрик.

\begin{figure}[h]
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=1\linewidth]{Presentation/materials/Pearson_all_data.png}
\includegraphics[width=1\linewidth]{Presentation/materials/Spearman_all_data.png}}
\end{minipage}
\hfill
\begin{minipage}[h]{0.49\linewidth}
\includegraphics[width=1\linewidth]{Presentation/materials/Accuracy_all_data.png}
На графиках представлены карты глубины, по осям которых расположены параметры модели, а глубина характеризует важные метрики. Лучше всего подойдут параметры из пересечения наибольших глубин.
$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;$
\end{minipage}
\end{figure}

%------------------------------------------------------------------------------------
\section{Вывод}

Алгоритм, приведенный в данной статье, действительно улучшил величину корреляции между энергиями связывания при сохранении качества классификации. Так для 1000 комплексов, оптимальными параметрами были $C_r = 1000, C = 178$ при которых $accuracy = 0.778$, $spearman = 0.504$, $pearson = 0.481$. Ожидается, что с увеличением числа объектов, качество модели существенно увеличится, но для этого необходимо иметь огромные вычислительные ресурсы.


%\section{Tables and figures}

%\begin{table}[h]
%\def~{\phantom0}
%\catcode`\@=13
%\def@{\phantom.}
%\caption{Some caption text.\label{tab-01}}
%\medskip
%\begin{center}
%\begin{tabular}{l|ccc}\hline
%\multicolumn1l{\it Some title}\\\hline\hline
%row 1, column 1         &   row 1, column 2  \\
%row 2, column 1    &   row 2, column 2   \\
%row 3, column 1    &   row 3, column 2   \\
%\hline
%\multicolumn1l{\it Another title} & Value 1 &   Value 2 &   Value 3 \\
%\hline\hline
%row 1                    & ~130 & 30 & 30 \\
%row 2                    & 1025 & ~1 & 15 \\
%row 3                   & ~100 & ~1 & 10 \\
%row 4        & 2925 & ~1 & ~4 \\
%row 5            & 2950 & ~1 & ~2 \\\hline
%\end{tabular}
%\end{center}
%\end{table}

%\begin{figure}[h]
%\caption{The graph of $y=x\,sin x$ in the interval [-50,50], created by wxMaxima %0.7.4. \label{fig_abc}}
%\vskip3cm
%\includegraphics{xsinx-49.png}
%\end{figure}

\newpage

\bibliographystyle{unsrt}
\bibliography{References}


\end{document}
